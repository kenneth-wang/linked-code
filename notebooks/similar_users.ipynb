{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "007cd81e",
   "metadata": {},
   "source": [
    "* [User -> Users (by language)](#User--%3E-Users-(by-language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1592c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import List\n",
    "\n",
    "from pyspark.ml.linalg import SparseVector\n",
    "from pyspark.sql.functions import collect_list, collect_set\n",
    "from pyspark.ml.feature import CountVectorizer, CountVectorizerModel\n",
    "from pyspark.rdd import RDD\n",
    "from pyspark import SparkConf, SparkContext, StorageLevel\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64ec7d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/10/31 15:59:03 WARN Utils: Your hostname, 15in.local resolves to a loopback address: 127.0.0.1; using 192.168.1.7 instead (on interface en0)\n",
      "21/10/31 15:59:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/raimibinkarim/.local/lib/python3.8/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/raimibinkarim/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/raimibinkarim/.ivy2/jars\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-a4f4c7b3-b709-48f3-8886-ce340678dde9;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;3.0.0 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;4.0.5 in central\n",
      "\tfound org.mongodb#bson;4.0.5 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;4.0.5 in central\n",
      ":: resolution report :: resolve 202ms :: artifacts dl 11ms\n",
      "\t:: modules in use:\n",
      "\torg.mongodb#bson;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;4.0.5 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;3.0.0 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   4   |   0   |   0   |   0   ||   4   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-a4f4c7b3-b709-48f3-8886-ce340678dde9\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 4 already retrieved (0kB/6ms)\n",
      "21/10/31 15:59:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .config(\"spark.mongodb.input.uri\", \"mongodb://localhost:27017/gh.users\")\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.0\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4120a31",
   "metadata": {},
   "source": [
    "## User -> Users (by language)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f462b714",
   "metadata": {},
   "source": [
    "Content-based filtering.\n",
    "\n",
    "Represent every user as a vector of language counts.\n",
    "\n",
    "Use cases:\n",
    "* Given a user, find similar user IDs.\n",
    "* Given a list of languages, find similar users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7bf19d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = (\n",
    "    spark.read\n",
    "    .format(\"com.mongodb.spark.sql.DefaultSource\")\n",
    "    .option(\"uri\",\"mongodb://localhost:27017/gh.repos\")\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "67aa2a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarUsersEngine:\n",
    "    \n",
    "    def __init__(self, model: CountVectorizerModel, schema, index: RDD):\n",
    "        self.model = model\n",
    "        self.schema = schema\n",
    "        self.index = index\n",
    "        \n",
    "    @classmethod\n",
    "    def start(cls, binarize: bool, limit: int = None):\n",
    "        \"\"\"\n",
    "        1. Load the repos data.\n",
    "        2. Count the languages for every user.\n",
    "        3. Fit to CountVectorizer\n",
    "        \"\"\"\n",
    "        repos = (\n",
    "            spark.read\n",
    "            .format(\"com.mongodb.spark.sql.DefaultSource\")\n",
    "            .option(\"uri\",\"mongodb://localhost:27017/gh.repos\")\n",
    "            .load()\n",
    "        )\n",
    "        if limit:\n",
    "            repos = repos.limit(limit)\n",
    "\n",
    "        language_counts = (\n",
    "            repos\n",
    "            .select([\"owner.login\",\"language\"])\n",
    "            .groupBy(\"login\")\n",
    "            .agg(collect_set(\"language\"))\n",
    "        )\n",
    "\n",
    "        cv = CountVectorizer(\n",
    "            inputCol=\"collect_set(language)\",\n",
    "            outputCol=\"features\",\n",
    "            binary=binarize,\n",
    "            minDF=0,\n",
    "        )\n",
    "        model = cv.fit(language_counts)\n",
    "    \n",
    "        index = (\n",
    "            model\n",
    "            .transform(language_counts)\n",
    "            .select([\"login\", \"features\"])\n",
    "            .rdd\n",
    "            .map(lambda row: (row[0],row[1]))\n",
    "            .persist(StorageLevel.MEMORY_AND_DISK)\n",
    "        )\n",
    "        \n",
    "        return cls(\n",
    "            model=model,\n",
    "            schema=language_counts.schema,\n",
    "            index=index,\n",
    "        )\n",
    "\n",
    "    def get_user_vector(self, login: str):\n",
    "        try:\n",
    "            query_user = self.index.filter(lambda user: user[0] == login).first()\n",
    "        except ValueError:\n",
    "            raise KeyError\n",
    "\n",
    "        return query_user\n",
    "        \n",
    "\n",
    "    def find_most_similar_users_by_languages(\n",
    "        self, \n",
    "        languages: List[str], \n",
    "        k: int = 5,\n",
    "        similarity=jaccard,\n",
    "    ) -> list:\n",
    "        \n",
    "        assert isinstance(languages, list)\n",
    "        \n",
    "        query: SparseVector = (\n",
    "            self.model\n",
    "            .transform(spark.createDataFrame([(0, languages)], self.schema))\n",
    "            .first()\n",
    "            .features\n",
    "        )\n",
    "        \n",
    "        ids = (\n",
    "            self.index\n",
    "            .mapValues(similarity)\n",
    "            .top(k, key=lambda x: x[1])\n",
    "        )\n",
    "\n",
    "        return ids\n",
    "    \n",
    "    def find_most_similar_users_by_login(\n",
    "        self, \n",
    "        login: str, \n",
    "        k: int = 5, \n",
    "        similarity=jaccard,\n",
    "    ) -> list:\n",
    "        \n",
    "        _, query = self.get_user_vector(login)\n",
    "        \n",
    "        ids = (\n",
    "            self.index\n",
    "            .mapValues(similarity)\n",
    "            .top(k, key=lambda x: x[1])\n",
    "        )\n",
    "\n",
    "        return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "355039ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(user, query):\n",
    "    return ((user.values > 0) * (query.values > 0)).sum()\n",
    "\n",
    "def euclidean(user, query):\n",
    "    return -user.squared_distance(query)\n",
    "\n",
    "def cosine(user, query):\n",
    "    dist = user.squared_distance(query)\n",
    "    return dist / (user.norm(2)*query.norm(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3266f4ff",
   "metadata": {},
   "source": [
    "No. of users with repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66fc6bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "445962"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.index.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f75935d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 113:=====================================================> (29 + 1) / 30]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.58094573020935\n"
     ]
    }
   ],
   "source": [
    "a = time.time()\n",
    "engine = SimilarUsersEngine.start(binarize=True)\n",
    "b = time.time()\n",
    "print(b-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "91c383c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = SparseVector(3, {0:10,1:10,2:8})\n",
    "u = SparseVector(3, {0: 0,1:10,2:8})\n",
    "v = SparseVector(3, {0:10,1:10,2:8})\n",
    "w = SparseVector(3, {0:10,1: 9,2:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "be652550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('getsentry', 4.0),\n",
       " ('microsoft', 4.0),\n",
       " ('TheAlgorithms', 4.0),\n",
       " ('discord', 4.0),\n",
       " ('pact-foundation', 4.0)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.find_most_similar_users_by_languages(\n",
    "    [\"Python\", \"Kotlin\", \"Rust\", \"JavaScript\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8b56de8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 102:==============>                                          (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.480223894119263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 102:=================================================>       (7 + 1) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "a = time.time()\n",
    "engine.find_most_similar_users_by_login(login=\"remykarem\")\n",
    "b = time.time()\n",
    "print(b-a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs5344] *",
   "language": "python",
   "name": "conda-env-cs5344-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
