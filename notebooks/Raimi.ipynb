{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "007cd81e",
   "metadata": {},
   "source": [
    "* [User -> Users (by language)](#User--%3E-Users-(by-language))\n",
    "* [Basket analysis](#Basket-analysis:-Starred-repos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1592c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ec7d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .config(\"spark.mongodb.input.uri\", \"mongodb://localhost:27017/gh.users\")\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.0\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4120a31",
   "metadata": {},
   "source": [
    "## User -> Users (by language)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f462b714",
   "metadata": {},
   "source": [
    "Content-based filtering.\n",
    "\n",
    "Represent every user as a vector of language counts.\n",
    "\n",
    "Use cases:\n",
    "* Given a user, find similar user IDs.\n",
    "* Given a list of languages, find similar users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62ea497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import SparseVector\n",
    "from pyspark.sql.functions import collect_list, collect_set\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91431b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "UserId = int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aa2a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarUsersEngine:\n",
    "    \n",
    "    def __init__(self, model, schema, language_counts):\n",
    "        self.model = model\n",
    "        self.schema = schema\n",
    "        self.language_counts = language_counts\n",
    "        \n",
    "    @classmethod\n",
    "    def start(cls):\n",
    "        repos = (\n",
    "            spark.read\n",
    "            .format(\"com.mongodb.spark.sql.DefaultSource\")\n",
    "            .option(\"uri\",\"mongodb://localhost:27017/gh.repos\")\n",
    "            .load()\n",
    "            .limit(1000)\n",
    "        )\n",
    "\n",
    "        language_counts = (\n",
    "            repos\n",
    "            .select([\"owner.id\",\"language\"])\n",
    "            .groupBy(\"id\")\n",
    "            .agg(collect_set(\"language\"))\n",
    "        )\n",
    "        # user1 [\"py\", \"js\", \"py\"]\n",
    "\n",
    "        cv = CountVectorizer(\n",
    "            inputCol=\"collect_set(language)\",\n",
    "            outputCol=\"features\",\n",
    "            binary=True,\n",
    "            minDF=0\n",
    "        )\n",
    "\n",
    "        return cls(\n",
    "            model=cv.fit(language_counts),\n",
    "            schema=language_counts.schema,\n",
    "            language_counts=language_counts,\n",
    "        )\n",
    "\n",
    "    def find_most_similar_users_by_languages(self, languages: List[str]) -> List[int]:\n",
    "        assert isinstance(languages, list)\n",
    "        \n",
    "        query = (\n",
    "            self.model\n",
    "            .transform(spark.createDataFrame([(0, languages)], self.language_counts.schema))\n",
    "            .first()\n",
    "            .features)\n",
    "        \n",
    "        result = self.model.transform(self.language_counts)\n",
    "\n",
    "        ids = (\n",
    "            result\n",
    "            .rdd\n",
    "            .map(lambda row: (row.id, row.features.dot(query)))\n",
    "            .filter(lambda row: row[1] > 0)\n",
    "            .map(lambda row: row[0])\n",
    "            .collect()\n",
    "        )\n",
    "\n",
    "        return ids\n",
    "    \n",
    "    def find_most_similar_users_by_id(self, user_id: UserId):\n",
    "        languages = engine.language_counts.rdd.filter(lambda row: row.id == user_id).first()[1]\n",
    "        return self.find_most_similar_users_by_languages(languages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f75935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = SimilarUsersEngine.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089b348b",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.find_most_similar_users_by_languages([\"Python\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9411b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.find_most_similar_users_by_id(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cd8ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_language_counts_per_owner(repos_ownership: list) -> dict:\n",
    "    \n",
    "    language_counts_per_owner = {}\n",
    "    \n",
    "    for _, owner_id, language in repos_ownership:\n",
    "        if owner_id in language_counts_per_owner:\n",
    "            language_counts = language_counts_per_owner[owner_id]\n",
    "            if language in language_counts:\n",
    "                language_counts[language] += 1\n",
    "            else:\n",
    "                language_counts[language] = 1\n",
    "        else:\n",
    "            language_counts_per_owner[owner_id] = {language: 1}\n",
    "\n",
    "    return language_counts_per_owner\n",
    "\n",
    "def get_repos_per_owner(repos_ownership: list) -> dict:\n",
    "\n",
    "    repos_per_owner = {}\n",
    "\n",
    "    for repo_id, owner_id, _ in repos_ownership:\n",
    "        if owner_id in repos_per_owner:\n",
    "            repos_per_owner[owner_id].add(repo_id)\n",
    "        else:\n",
    "            repos_per_owner[owner_id] = set([repo_id])\n",
    "\n",
    "    return repos_per_owner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604ea5bf",
   "metadata": {},
   "source": [
    "# Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195b930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = (\n",
    "    spark.read\n",
    "    .format(\"com.mongodb.spark.sql.DefaultSource\")\n",
    "    .option(\"uri\",\"mongodb://localhost:27017/gh.repos\")\n",
    "    .load()\n",
    "    .limit(100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3451bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = (\n",
    "    spark.read\n",
    "    .format(\"com.mongodb.spark.sql.DefaultSource\")\n",
    "    .option(\"uri\",\"mongodb://localhost:27017/gh.users\")\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163e5a9d",
   "metadata": {},
   "source": [
    "relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141ffe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = repos.select([\n",
    "    \"_id\",\n",
    "    \"full_name\", \n",
    "    \"description\",\n",
    "    \"language\",\n",
    "    \"owner\",\n",
    "    \"updated_at\",       # scope last 5 years\n",
    "    \"fork\",             # scope = false\n",
    "    \"stargazers_count\", # popularity\n",
    "    \"created_at\",       # recency\n",
    "    \"size\",             # maturity, complexity\n",
    "])\n",
    "\n",
    "repos = repos.filter(repos.fork == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b2a0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "underdogs = (repos\n",
    "    .filter((repos.language == \"Rust\") & (repos.stargazers_count < 10))\n",
    ")\n",
    "\n",
    "underdogs.sort(underdogs.created_at.desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53aab2c",
   "metadata": {},
   "source": [
    "# Basket analysis: Starred repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23acf45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction = [repoid1, repoid6, repoid10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd6fd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = {\n",
    "    '$match': {'starred.0': {'$type': 'number'}}\n",
    "}\n",
    "\n",
    "valid_users = (\n",
    "    spark.read\n",
    "    .format(\"com.mongodb.spark.sql.DefaultSource\")\n",
    "    .option(\"uri\", \"mongodb://localhost:27017/gh.users\")\n",
    "    .option(\"pipeline\", str(pipeline))\n",
    "    .load()\n",
    "    .limit(10)\n",
    ")\n",
    "\n",
    "transactions = (valid_users\n",
    "    .select([\"_id\", \"starred\"])\n",
    "    .rdd.map(lambda a: set(a.starred))\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6ee356",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = []\n",
    "for t in transactions:\n",
    "    l = set()\n",
    "    for item in t:\n",
    "        item = str(item)\n",
    "        l.add(item)\n",
    "    h.append(l)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8242902d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from apriori import generate_frequent_itemsets_id, apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7bc821",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "rules, _ = apriori(h, 0.1, 0.1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ac71ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20fd370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from apyori import TransactionManager, gen_support_records, apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9560085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(t) for t in transactions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78ba174",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install apyori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8000821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0767bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "transaction_manager = TransactionManager.create(transactions)\n",
    "support_records = list(gen_support_records(transaction_manager, 0.1, max_length=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a253d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(apriori(transactions, min_support=0.1, min_confidence=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a20cb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs5344] *",
   "language": "python",
   "name": "conda-env-cs5344-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
